{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder and GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is made available by UCI. It contains data about patients with and without heart problems. Each row represents a single patient. There two files: heart-normal (contains patients without any heart problems) and heart_anomaly (contains patients with heart problems). Anomaly detection task: build an autoencoder on normal patients to identify anomalous observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **heart-normal.csv** data set to train an autoencoder on healthy (i.e., normal) patients. Then, use the observations in **heart-anomaly.csv** data set to check whether the autoencoder can successfully detect patients who have a heart anomaly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in normal dataset\n",
    "heart_normal = pd.read_csv(\"heart_normal.csv\")\n",
    "heart_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   67    1   0       160   286    0        0      108      1      1.5      1   \n",
       "1   67    1   0       120   229    0        0      129      1      2.6      1   \n",
       "2   62    0   0       140   268    0        0      160      0      3.6      0   \n",
       "3   63    1   0       130   254    0        0      147      0      1.4      1   \n",
       "4   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "\n",
       "   ca  thal  \n",
       "0   3     2  \n",
       "1   2     3  \n",
       "2   2     2  \n",
       "3   1     3  \n",
       "4   0     3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in anomalous dataset\n",
    "heart_anomaly = pd.read_csv(\"heart_anomaly.csv\")\n",
    "heart_anomaly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fit transform normal\n",
    "heart_normal_std = scaler.fit_transform(heart_normal)\n",
    "\n",
    "#transform anomaly\n",
    "heart_anomaly_std = scaler.transform(heart_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165, 13), (20, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_normal_std.shape, heart_anomaly_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 11)                154       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 11)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 13)                156       \n",
      "=================================================================\n",
      "Total params: 618\n",
      "Trainable params: 618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#Encoder - progressively reduce neurons\n",
    "model.add(keras.layers.Input(shape=13))\n",
    "model.add(keras.layers.Dense(11, activation='selu'))\n",
    "model.add(keras.layers.Dense(9, activation='selu'))\n",
    "\n",
    "#Decoder - progressively increase neurons\n",
    "model.add(keras.layers.Dense(9, activation='selu'))\n",
    "model.add(keras.layers.Dense(11, activation='selu'))\n",
    "model.add(keras.layers.Dense(13))     # no activation for ouput layer since inputs are continuous\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define learning rate\n",
    "lr = 0.001\n",
    "\n",
    "#Available optimizers:\n",
    "adagrad = keras.optimizers.Adagrad(lr=lr, epsilon=None, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=lr, momentum=0.9, decay=0.0, nesterov=True)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "nesterov_adam = keras.optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "#Initializations:\n",
    "xavier = keras.initializers.glorot_normal(seed=None)\n",
    "he = keras.initializers.he_normal(seed=None)\n",
    "\n",
    "# Activation functions\n",
    "activation = 'elu' \n",
    "#activation = 'relu'\n",
    "#activation = 'tanh'\n",
    "#activation = 'sigmoid'\n",
    "\n",
    "#Compile model using Nadam optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer=nesterov_adam, metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define early-stopping parameters\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5436 - mean_squared_error: 0.5436 - val_loss: 0.5415 - val_mean_squared_error: 0.5415\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5414 - mean_squared_error: 0.5414 - val_loss: 0.5392 - val_mean_squared_error: 0.5392\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5390 - mean_squared_error: 0.5390 - val_loss: 0.5370 - val_mean_squared_error: 0.5370\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5369 - mean_squared_error: 0.5369 - val_loss: 0.5347 - val_mean_squared_error: 0.5347\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5345 - mean_squared_error: 0.5345 - val_loss: 0.5325 - val_mean_squared_error: 0.5325\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5323 - mean_squared_error: 0.5323 - val_loss: 0.5303 - val_mean_squared_error: 0.5303\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5301 - mean_squared_error: 0.5301 - val_loss: 0.5281 - val_mean_squared_error: 0.5281\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5280 - mean_squared_error: 0.5280 - val_loss: 0.5259 - val_mean_squared_error: 0.5259\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5258 - mean_squared_error: 0.5258 - val_loss: 0.5237 - val_mean_squared_error: 0.5237\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5236 - mean_squared_error: 0.5236 - val_loss: 0.5215 - val_mean_squared_error: 0.5215\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5213 - mean_squared_error: 0.5213 - val_loss: 0.5194 - val_mean_squared_error: 0.5194\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5192 - mean_squared_error: 0.5192 - val_loss: 0.5172 - val_mean_squared_error: 0.5172\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5313 - mean_squared_error: 0.53 - 0s 8ms/step - loss: 0.5170 - mean_squared_error: 0.5170 - val_loss: 0.5150 - val_mean_squared_error: 0.5150\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5150 - mean_squared_error: 0.5150 - val_loss: 0.5129 - val_mean_squared_error: 0.5129\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5128 - mean_squared_error: 0.5128 - val_loss: 0.5108 - val_mean_squared_error: 0.5108\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5107 - mean_squared_error: 0.5107 - val_loss: 0.5088 - val_mean_squared_error: 0.5088\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5087 - mean_squared_error: 0.5087 - val_loss: 0.5068 - val_mean_squared_error: 0.5068\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5067 - mean_squared_error: 0.5067 - val_loss: 0.5048 - val_mean_squared_error: 0.5048\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5047 - mean_squared_error: 0.5047 - val_loss: 0.5028 - val_mean_squared_error: 0.5028\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5027 - mean_squared_error: 0.5027 - val_loss: 0.5008 - val_mean_squared_error: 0.5008\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5008 - mean_squared_error: 0.5008 - val_loss: 0.4989 - val_mean_squared_error: 0.4989\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4988 - mean_squared_error: 0.4988 - val_loss: 0.4968 - val_mean_squared_error: 0.4968\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4968 - mean_squared_error: 0.4968 - val_loss: 0.4948 - val_mean_squared_error: 0.4948\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4947 - mean_squared_error: 0.4947 - val_loss: 0.4928 - val_mean_squared_error: 0.4928\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4927 - mean_squared_error: 0.4927 - val_loss: 0.4908 - val_mean_squared_error: 0.4908\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4907 - mean_squared_error: 0.4907 - val_loss: 0.4889 - val_mean_squared_error: 0.4889\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4887 - mean_squared_error: 0.4887 - val_loss: 0.4869 - val_mean_squared_error: 0.4869\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4868 - mean_squared_error: 0.4868 - val_loss: 0.4850 - val_mean_squared_error: 0.4850\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4849 - mean_squared_error: 0.4849 - val_loss: 0.4830 - val_mean_squared_error: 0.4830\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4830 - mean_squared_error: 0.4830 - val_loss: 0.4812 - val_mean_squared_error: 0.4812\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4811 - mean_squared_error: 0.4811 - val_loss: 0.4793 - val_mean_squared_error: 0.4793\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4792 - mean_squared_error: 0.4792 - val_loss: 0.4774 - val_mean_squared_error: 0.4774\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4773 - mean_squared_error: 0.4773 - val_loss: 0.4755 - val_mean_squared_error: 0.4755\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4755 - mean_squared_error: 0.4755 - val_loss: 0.4737 - val_mean_squared_error: 0.4737\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4737 - mean_squared_error: 0.4737 - val_loss: 0.4718 - val_mean_squared_error: 0.4718\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4718 - mean_squared_error: 0.4718 - val_loss: 0.4700 - val_mean_squared_error: 0.4700\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4699 - mean_squared_error: 0.4699 - val_loss: 0.4681 - val_mean_squared_error: 0.4681\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4680 - mean_squared_error: 0.4680 - val_loss: 0.4663 - val_mean_squared_error: 0.4663\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4664 - mean_squared_error: 0.4664 - val_loss: 0.4645 - val_mean_squared_error: 0.4645\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4644 - mean_squared_error: 0.4644 - val_loss: 0.4627 - val_mean_squared_error: 0.4627\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4625 - mean_squared_error: 0.4625 - val_loss: 0.4609 - val_mean_squared_error: 0.4609\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4607 - mean_squared_error: 0.4607 - val_loss: 0.4590 - val_mean_squared_error: 0.4590\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4590 - mean_squared_error: 0.4590 - val_loss: 0.4572 - val_mean_squared_error: 0.4572\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4571 - mean_squared_error: 0.4571 - val_loss: 0.4554 - val_mean_squared_error: 0.4554\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4553 - mean_squared_error: 0.4553 - val_loss: 0.4536 - val_mean_squared_error: 0.4536\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4535 - mean_squared_error: 0.4535 - val_loss: 0.4517 - val_mean_squared_error: 0.4517\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4517 - mean_squared_error: 0.4517 - val_loss: 0.4499 - val_mean_squared_error: 0.4499\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4499 - mean_squared_error: 0.4499 - val_loss: 0.4481 - val_mean_squared_error: 0.4481\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4481 - mean_squared_error: 0.4481 - val_loss: 0.4463 - val_mean_squared_error: 0.4463\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4463 - mean_squared_error: 0.4463 - val_loss: 0.4445 - val_mean_squared_error: 0.4445\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4445 - mean_squared_error: 0.4445 - val_loss: 0.4428 - val_mean_squared_error: 0.4428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4427 - mean_squared_error: 0.4427 - val_loss: 0.4409 - val_mean_squared_error: 0.4409\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4409 - mean_squared_error: 0.4409 - val_loss: 0.4392 - val_mean_squared_error: 0.4392\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4391 - mean_squared_error: 0.4391 - val_loss: 0.4374 - val_mean_squared_error: 0.4374\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4048 - mean_squared_error: 0.40 - 0s 7ms/step - loss: 0.4372 - mean_squared_error: 0.4372 - val_loss: 0.4356 - val_mean_squared_error: 0.4356\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4355 - mean_squared_error: 0.4355 - val_loss: 0.4338 - val_mean_squared_error: 0.4338\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4337 - mean_squared_error: 0.4337 - val_loss: 0.4320 - val_mean_squared_error: 0.4320\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4319 - mean_squared_error: 0.4319 - val_loss: 0.4302 - val_mean_squared_error: 0.4302\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4302 - mean_squared_error: 0.4302 - val_loss: 0.4284 - val_mean_squared_error: 0.4284\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4285 - mean_squared_error: 0.4285 - val_loss: 0.4266 - val_mean_squared_error: 0.4266\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4266 - mean_squared_error: 0.4266 - val_loss: 0.4249 - val_mean_squared_error: 0.4249\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4250 - mean_squared_error: 0.4250 - val_loss: 0.4232 - val_mean_squared_error: 0.4232\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4089 - mean_squared_error: 0.40 - 0s 7ms/step - loss: 0.4231 - mean_squared_error: 0.4231 - val_loss: 0.4214 - val_mean_squared_error: 0.4214\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4214 - mean_squared_error: 0.4214 - val_loss: 0.4197 - val_mean_squared_error: 0.4197\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4196 - mean_squared_error: 0.4196 - val_loss: 0.4179 - val_mean_squared_error: 0.4179\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4179 - mean_squared_error: 0.4179 - val_loss: 0.4162 - val_mean_squared_error: 0.4162\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4162 - mean_squared_error: 0.4162 - val_loss: 0.4144 - val_mean_squared_error: 0.4144\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4143 - mean_squared_error: 0.4143 - val_loss: 0.4126 - val_mean_squared_error: 0.4126\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4126 - mean_squared_error: 0.4126 - val_loss: 0.4109 - val_mean_squared_error: 0.4109\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4108 - mean_squared_error: 0.4108 - val_loss: 0.4091 - val_mean_squared_error: 0.4091\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4090 - mean_squared_error: 0.4090 - val_loss: 0.4073 - val_mean_squared_error: 0.4073\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4072 - mean_squared_error: 0.4072 - val_loss: 0.4055 - val_mean_squared_error: 0.4055\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4054 - mean_squared_error: 0.4054 - val_loss: 0.4038 - val_mean_squared_error: 0.4038\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4037 - mean_squared_error: 0.4037 - val_loss: 0.4020 - val_mean_squared_error: 0.4020\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4020 - mean_squared_error: 0.4020 - val_loss: 0.4003 - val_mean_squared_error: 0.4003\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4001 - mean_squared_error: 0.4001 - val_loss: 0.3985 - val_mean_squared_error: 0.3985\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3984 - mean_squared_error: 0.3984 - val_loss: 0.3968 - val_mean_squared_error: 0.3968\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3968 - mean_squared_error: 0.3968 - val_loss: 0.3951 - val_mean_squared_error: 0.3951\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3951 - mean_squared_error: 0.3951 - val_loss: 0.3934 - val_mean_squared_error: 0.3934\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3934 - mean_squared_error: 0.3934 - val_loss: 0.3917 - val_mean_squared_error: 0.3917\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3917 - mean_squared_error: 0.3917 - val_loss: 0.3900 - val_mean_squared_error: 0.3900\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3901 - mean_squared_error: 0.3901 - val_loss: 0.3884 - val_mean_squared_error: 0.3884\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3883 - mean_squared_error: 0.3883 - val_loss: 0.3867 - val_mean_squared_error: 0.3867\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3867 - mean_squared_error: 0.3867 - val_loss: 0.3851 - val_mean_squared_error: 0.3851\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3850 - mean_squared_error: 0.3850 - val_loss: 0.3834 - val_mean_squared_error: 0.3834\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3835 - mean_squared_error: 0.3835 - val_loss: 0.3818 - val_mean_squared_error: 0.3818\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3818 - mean_squared_error: 0.3818 - val_loss: 0.3803 - val_mean_squared_error: 0.3803\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.3787 - val_mean_squared_error: 0.3787\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3788 - mean_squared_error: 0.3788 - val_loss: 0.3771 - val_mean_squared_error: 0.3771\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3771 - mean_squared_error: 0.3771 - val_loss: 0.3756 - val_mean_squared_error: 0.3756\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3756 - mean_squared_error: 0.3756 - val_loss: 0.3741 - val_mean_squared_error: 0.3741\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3740 - mean_squared_error: 0.3740 - val_loss: 0.3726 - val_mean_squared_error: 0.3726\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3726 - mean_squared_error: 0.3726 - val_loss: 0.3712 - val_mean_squared_error: 0.3712\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3710 - mean_squared_error: 0.3710 - val_loss: 0.3697 - val_mean_squared_error: 0.3697\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3739 - mean_squared_error: 0.37 - 0s 8ms/step - loss: 0.3697 - mean_squared_error: 0.3697 - val_loss: 0.3683 - val_mean_squared_error: 0.3683\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3683 - mean_squared_error: 0.3683 - val_loss: 0.3669 - val_mean_squared_error: 0.3669\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3668 - mean_squared_error: 0.3668 - val_loss: 0.3655 - val_mean_squared_error: 0.3655\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3656 - mean_squared_error: 0.3656 - val_loss: 0.3642 - val_mean_squared_error: 0.3642\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3642 - mean_squared_error: 0.3642 - val_loss: 0.3629 - val_mean_squared_error: 0.3629\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3628 - mean_squared_error: 0.3628 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3616 - mean_squared_error: 0.3616 - val_loss: 0.3603 - val_mean_squared_error: 0.3603\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3602 - mean_squared_error: 0.3602 - val_loss: 0.3591 - val_mean_squared_error: 0.3591\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3590 - mean_squared_error: 0.3590 - val_loss: 0.3578 - val_mean_squared_error: 0.3578\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3578 - mean_squared_error: 0.3578 - val_loss: 0.3565 - val_mean_squared_error: 0.3565\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3566 - mean_squared_error: 0.3566 - val_loss: 0.3553 - val_mean_squared_error: 0.3553\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 0.3541 - val_mean_squared_error: 0.3541\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3541 - mean_squared_error: 0.3541 - val_loss: 0.3529 - val_mean_squared_error: 0.3529\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3529 - mean_squared_error: 0.3529 - val_loss: 0.3517 - val_mean_squared_error: 0.3517\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3517 - mean_squared_error: 0.3517 - val_loss: 0.3505 - val_mean_squared_error: 0.3505\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.3494 - val_mean_squared_error: 0.3494\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3493 - mean_squared_error: 0.3493 - val_loss: 0.3482 - val_mean_squared_error: 0.3482\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3482 - mean_squared_error: 0.3482 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3471 - mean_squared_error: 0.3471 - val_loss: 0.3459 - val_mean_squared_error: 0.3459\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3459 - mean_squared_error: 0.3459 - val_loss: 0.3448 - val_mean_squared_error: 0.3448\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3448 - mean_squared_error: 0.3448 - val_loss: 0.3437 - val_mean_squared_error: 0.3437\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3437 - mean_squared_error: 0.3437 - val_loss: 0.3426 - val_mean_squared_error: 0.3426\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3427 - mean_squared_error: 0.3427 - val_loss: 0.3415 - val_mean_squared_error: 0.3415\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3415 - mean_squared_error: 0.3415 - val_loss: 0.3404 - val_mean_squared_error: 0.3404\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3405 - mean_squared_error: 0.3405 - val_loss: 0.3394 - val_mean_squared_error: 0.3394\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3394 - mean_squared_error: 0.3394 - val_loss: 0.3383 - val_mean_squared_error: 0.3383\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3384 - mean_squared_error: 0.3384 - val_loss: 0.3373 - val_mean_squared_error: 0.3373\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3373 - mean_squared_error: 0.3373 - val_loss: 0.3362 - val_mean_squared_error: 0.3362\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3363 - mean_squared_error: 0.3363 - val_loss: 0.3352 - val_mean_squared_error: 0.3352\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3352 - mean_squared_error: 0.3352 - val_loss: 0.3342 - val_mean_squared_error: 0.3342\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3342 - mean_squared_error: 0.3342 - val_loss: 0.3332 - val_mean_squared_error: 0.3332\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3333 - mean_squared_error: 0.3333 - val_loss: 0.3322 - val_mean_squared_error: 0.3322\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3322 - mean_squared_error: 0.3322 - val_loss: 0.3311 - val_mean_squared_error: 0.3311\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.3301 - val_mean_squared_error: 0.3301\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.3290 - val_mean_squared_error: 0.3290\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3291 - mean_squared_error: 0.3291 - val_loss: 0.3280 - val_mean_squared_error: 0.3280\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.3270 - val_mean_squared_error: 0.3270\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.3259 - val_mean_squared_error: 0.3259\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3259 - mean_squared_error: 0.3259 - val_loss: 0.3249 - val_mean_squared_error: 0.3249\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.3239 - val_mean_squared_error: 0.3239\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3239 - mean_squared_error: 0.3239 - val_loss: 0.3228 - val_mean_squared_error: 0.3228\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.3218 - val_mean_squared_error: 0.3218\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3208 - val_mean_squared_error: 0.3208\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.3198 - val_mean_squared_error: 0.3198\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3198 - mean_squared_error: 0.3198 - val_loss: 0.3187 - val_mean_squared_error: 0.3187\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3187 - mean_squared_error: 0.3187 - val_loss: 0.3177 - val_mean_squared_error: 0.3177\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3177 - mean_squared_error: 0.3177 - val_loss: 0.3166 - val_mean_squared_error: 0.3166\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3167 - mean_squared_error: 0.3167 - val_loss: 0.3156 - val_mean_squared_error: 0.3156\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3157 - mean_squared_error: 0.3157 - val_loss: 0.3146 - val_mean_squared_error: 0.3146\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3146 - mean_squared_error: 0.3146 - val_loss: 0.3135 - val_mean_squared_error: 0.3135\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3135 - mean_squared_error: 0.3135 - val_loss: 0.3125 - val_mean_squared_error: 0.3125\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3125 - mean_squared_error: 0.3125 - val_loss: 0.3114 - val_mean_squared_error: 0.3114\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3115 - mean_squared_error: 0.3115 - val_loss: 0.3103 - val_mean_squared_error: 0.3103\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3103 - mean_squared_error: 0.3103 - val_loss: 0.3093 - val_mean_squared_error: 0.3093\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3094 - mean_squared_error: 0.3094 - val_loss: 0.3082 - val_mean_squared_error: 0.3082\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3082 - mean_squared_error: 0.3082 - val_loss: 0.3071 - val_mean_squared_error: 0.3071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ba1e7cb50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model using normal dataset\n",
    "model.fit(heart_normal_std, heart_normal_std, \n",
    "          validation_data = (heart_normal_std, heart_normal_std),\n",
    "          epochs=150, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the average MSE on the \"normal\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 831us/step - loss: 0.3071 - mean_squared_error: 0.3071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3071291446685791, 0.3071291148662567]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(heart_normal_std, heart_normal_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the average MSE on the \"anomalous\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7216 - mean_squared_error: 0.7216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7215893864631653, 0.7215893864631653]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(heart_anomaly_std, heart_anomaly_std)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MSE on anomalous data is more than double that of the normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict first 20 in normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.20077400698803\n",
      "108.0323876232637\n",
      "16.86513164557531\n",
      "17.491780917573305\n",
      "38.39224302014403\n",
      "31.4315651950609\n",
      "7.917338086099719\n",
      "9.353659691451433\n",
      "31.69405746281771\n",
      "25.151877607206348\n",
      "11.760038508137091\n",
      "19.226134584782592\n",
      "10.216019723494002\n",
      "47.83772195730014\n",
      "18.381826425373422\n",
      "14.321221372162949\n",
      "20.27706038743175\n",
      "35.22579933028892\n",
      "34.755953388678606\n",
      "40.10043202057958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for i in range(0,20):\n",
    "    prediction = model.predict(heart_normal_std[i:i+1])\n",
    "    print((mean_squared_error(heart_normal_std[i:i+1], prediction))*100)\n",
    "    \n",
    "#Error terms are multiplied by 100 to make sense of the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all 20 in anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9091.148114043328\n",
      "9294.896658594946\n",
      "15097.924898732083\n",
      "5732.6237652421805\n",
      "11221.010327301316\n",
      "5808.499371932188\n",
      "1458.4131929357118\n",
      "2109.927403811218\n",
      "10561.739586586216\n",
      "8022.078200154128\n",
      "9731.577971712724\n",
      "7368.822528473503\n",
      "3166.102369397873\n",
      "9343.649677373847\n",
      "3277.4492848985597\n",
      "4976.412495243414\n",
      "14531.92302781102\n",
      "1442.4777641583091\n",
      "4050.669814714267\n",
      "8030.519503528285\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    prediction = model.predict(heart_anomaly_std[i:i+1])\n",
    "    print(100*(mean_squared_error(heart_anomaly_std[i:i+1], prediction))*100)\n",
    "    \n",
    "#Error terms are multiplied by 100 to make sense of the numbers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model is effective at detecting patients with heart anomalies because the error terms of the anomalous data are high enough to be easily distinguished from those of the normal data. Most of the MSEs of the normal data are around 30, with the highest being 108. In contrast, all of the MSEs of the anomalous data are above 1000, with the lowest being 1442. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GAN\n",
    "\n",
    "Build a GAN that can generate patients with heart anomalies. Test the effectiveness of the GAN using the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 13)                338       \n",
      "=================================================================\n",
      "Total params: 1,763\n",
      "Trainable params: 1,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#number of input variables\n",
    "codings_size = 30   \n",
    "\n",
    "#define the generator\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=codings_size),\n",
    "    keras.layers.Dense(25, activation=\"selu\"),\n",
    "    keras.layers.Dense(25, activation=\"selu\"),\n",
    "    keras.layers.Dense(13, activation=None) #no activation due to continous vars\n",
    "])\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 25)                350       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 1,026\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the discriminator\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=[13]),\n",
    "    keras.layers.Dense(25, activation=\"selu\"),\n",
    "    keras.layers.Dense(25, activation=\"selu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\") #1 neuron output - binary classification (real/fake)\n",
    "])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define GAN model\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "#compile discriminator\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "\n",
    "#compile GAN\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine input dataset for generator\n",
    "batch_size = 10\n",
    "dataset = tf.data.Dataset.from_tensor_slices(heart_anomaly_std).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train_gan function - 15 epochs\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=15):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_data = tf.cast(generator(noise), tf.float64)\n",
    "            X_fake_and_real = tf.concat([generated_data, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        print(\"Epoch: {}/{}\".format(epoch, n_epochs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/15\n",
      "Epoch: 1/15\n",
      "Epoch: 2/15\n",
      "Epoch: 3/15\n",
      "Epoch: 4/15\n",
      "Epoch: 5/15\n",
      "Epoch: 6/15\n",
      "Epoch: 7/15\n",
      "Epoch: 8/15\n",
      "Epoch: 9/15\n",
      "Epoch: 10/15\n",
      "Epoch: 11/15\n",
      "Epoch: 12/15\n",
      "Epoch: 13/15\n",
      "Epoch: 14/15\n"
     ]
    }
   ],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new data using trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 13), dtype=float64, numpy=\n",
       "array([[-1.51731205,  1.17190707,  1.31554747,  0.30161977,  2.1152215 ,\n",
       "        -0.30834025, -0.08885502,  1.3466531 ,  0.08363234,  0.34198651,\n",
       "        -0.03918867, -0.32027131,  0.737701  ],\n",
       "       [ 0.31898195,  1.05178297, -0.35875118,  0.69852394, -0.39236924,\n",
       "        -1.49213016,  1.36047769, -0.25507545,  0.8817628 , -0.65677702,\n",
       "         0.34380084,  0.81756979, -1.34627461],\n",
       "       [-0.3749606 , -0.72759658,  1.88149822, -0.13057487, -0.85450542,\n",
       "        -0.05750478, -1.21586359,  0.00722514, -0.18779019,  2.53429961,\n",
       "        -0.7722373 ,  0.43467569,  1.28557539],\n",
       "       [ 1.18621111,  1.10002673,  1.05017281,  0.87861317,  1.11924279,\n",
       "        -1.7135545 ,  1.00956678, -0.3426277 ,  1.25140548, -2.63345075,\n",
       "        -0.58396989,  1.0251199 , -0.66922277],\n",
       "       [ 0.3209154 , -0.14166456,  0.04485056,  0.15100434, -1.35214496,\n",
       "        -0.52834725, -2.57674885, -3.69230771,  0.22196059,  0.15067512,\n",
       "        -0.07310046, -0.23479939,  0.59739184],\n",
       "       [ 1.85496593, -0.03223894,  0.81924969,  0.4830761 , -2.53435326,\n",
       "        -1.88445497,  1.06073833, -1.21609724, -0.22861877, -0.05459732,\n",
       "         2.18172765,  0.64007783, -1.35677397],\n",
       "       [-1.63709092, -2.15977359,  1.09753561,  0.50892949, -1.74683893,\n",
       "         0.13973369, -2.60900736,  1.30663979,  0.05212471,  2.8572638 ,\n",
       "         0.18271148, -0.22489265,  1.36422682],\n",
       "       [ 0.08785225,  1.81298244, -0.84571767, -2.65153623,  0.63045508,\n",
       "         0.95909715, -0.81447631, -0.71127069, -0.38855821, -0.98697186,\n",
       "         0.78863448, -0.32429928,  0.33039901],\n",
       "       [-0.36990076, -3.93407655, -1.50025809, -1.85201836, -1.64870358,\n",
       "         1.84607196, -1.85788858, -0.37315807, -1.29986024,  2.10551047,\n",
       "         1.38339162, -0.81980449,  1.52125835],\n",
       "       [-0.02981421, -0.28636736, -1.9729017 ,  2.4506793 ,  1.3473016 ,\n",
       "        -0.54330349,  2.32167315,  0.86193711,  2.75751305, -1.46592712,\n",
       "         1.48980665,  0.65242195, -1.55607271]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate 10 rows of fake data\n",
    "noise = tf.random.normal(shape=[10, codings_size])\n",
    "generated_data = tf.cast(generator(noise), tf.float64)\n",
    "\n",
    "generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data against Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3058.1423979961246\n",
      "3057.2961043870528\n",
      "2978.2070502151587\n",
      "9331.885846453491\n",
      "11534.433271586493\n",
      "7559.766074981058\n",
      "12888.898050971065\n",
      "8104.466128051596\n",
      "22774.111452012872\n"
     ]
    }
   ],
   "source": [
    "#print MSEs of the 10 rows of generated data\n",
    "for i in range(0,9):\n",
    "    prediction = model.predict(generated_data[i:i+1])\n",
    "    print(100*(mean_squared_error(generated_data[i:i+1], prediction))*100)\n",
    "    \n",
    "#Error terms are multiplied by 100 to make sense of the numbers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Judging by the MSEs of the data generated by the GAN, the GAN is capable of producing plausible fake patients with heart anomalies. This is evident because the minimum MSE of the GAN-generated data is 2978, while the minimum MSE of the heart_anomaly data was 1442, meaning the fake data is well within the error range of the real data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
